{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "25e76b91ebd4420cbf9a94e42d48c020d009d1c7"
   },
   "source": [
    "  # What's Cooking? üòãüçú"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "c109f5b8ffe714839e25d60709e1e20c6cfe7b7e"
   },
   "source": [
    "![Food Map](https://pbs.twimg.com/media/C81zFXiXoAAYkXf.jpg:large)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "51f395adb1e9630945289bbedbecb13ec7552a78"
   },
   "source": [
    "This Kaggle competition asks us to predict the category of a dish's cuisine given a list of its ingredients. The dataset is provided by Yummly.  Be careful because working on this data can make you really hungry!!! üòã  <br><br>\n",
    "This notebook provides a step-by-step analysis and solution to the given problem. It can also serve as a great starting point for learning how to explore, manipulate, transform and learn from textual data. It is divided into three main sections: \n",
    "- Exploratory Analysis - as a first step, we explore the main characteristics of the data with the help of Plotly vizualizations; \n",
    "- Text Processing - here we apply some basic text processing techniques in order to clean and prepare the data for model development; \n",
    "- Feature Engineering & Data Modeling - in this section we extract features from data and build a predictive model of the cuisine.  <br>\n",
    "\n",
    "\n",
    " **And now..let the cooking in Jupyter Notebook begin! ü•ß **\n",
    " \n",
    " Author: Gloria Hristova - https://www.kaggle.com/gloriahristova"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "f46ca5fa997dd05007f30c89936831ee22c4912a"
   },
   "source": [
    "  # I.What's Cooking? - Exploratory Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "ef2fe62b3bd85cafd1f4c94c1242f02a1539c77c"
   },
   "source": [
    "###  * 1) Load necessary libraries*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_uuid": "db1934851cc930a02a5310849975089e1bc74ea2"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'plotly'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-ca2413bc7c72>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;31m# Data vizualizations\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mrandom\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mplotly\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mplotly\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtools\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mplotly\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moffline\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdownload_plotlyjs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minit_notebook_mode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mplot\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miplot\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'plotly'"
     ]
    }
   ],
   "source": [
    "# Data processing \n",
    "import pandas as pd\n",
    "import json\n",
    "from collections import Counter\n",
    "from itertools import chain\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "# Data vizualizations\n",
    "import random\n",
    "import plotly\n",
    "from plotly import tools\n",
    "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot \n",
    "init_notebook_mode(connected=True)\n",
    "import plotly.offline as offline\n",
    "import plotly.graph_objs as go\n",
    "\n",
    "# Data Modeling\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn import model_selection \n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "9a4ccb1f79553fb40f7c2fb34b343b62b152a38d"
   },
   "source": [
    "### * 2) Import json files with train and test samples *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "dabe264eae287a5190f9af4ae3094721870d82e8"
   },
   "outputs": [],
   "source": [
    "train_data = pd.read_json('train.json') # store as dataframe objects\n",
    "test_data = pd.read_json('test.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "fbf05f17029ea2d4c63daa6bc7298ff712459413"
   },
   "source": [
    "#### *Initial look of the training data:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "ad51c880d04ade7cec7b5fb034be5a820e334ce7"
   },
   "outputs": [],
   "source": [
    "train_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "2b269038d4f9c980158608ccc22bc78d69b7c2e0"
   },
   "outputs": [],
   "source": [
    "train_data.shape # 39774 observations, 3 columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "9593d4b55f4882b8ad58b3b131657e752563bffc"
   },
   "outputs": [],
   "source": [
    "print(\"The training data consists of {} recipes\".format(len(train_data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "a9dc5b6c5557e78b7bbc54bd0eefb92a6f97243d"
   },
   "outputs": [],
   "source": [
    "print(\"First five elements in our training sample:\")\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "d1ee4761e6684e3b34fdfa293f4b36cd090d35e4"
   },
   "source": [
    "#### *Take a quick look on test sample also:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "067acdb514b4f31d936425e9b1f35a89dbd83663"
   },
   "outputs": [],
   "source": [
    "test_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "93ba672e158e0463e9bb5c04185b3f41aa033451"
   },
   "outputs": [],
   "source": [
    "test_data.shape # 9944 observations, 2 columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "d5dfb7aec4bfa86b8ea24e5bb653282c72230b67"
   },
   "outputs": [],
   "source": [
    "print(\"The test data consists of {} recipes\".format(len(test_data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "a7e1db4987603d9e1107f120b76a5f3b5cf9a35d"
   },
   "outputs": [],
   "source": [
    "print(\"First five elements in our test sample:\")\n",
    "test_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "fd9325d49d409acd795e0cd9dca7079c9b8480e5"
   },
   "source": [
    "The test and train data provided in this Kaggle competition are in json format. We have imported the data as a data frame object and the above lines of code show us the initial look of both samples. We observe that each recipe is a separate row and has:\n",
    "- a unique identifier - the 'id' column; \n",
    "- the type of cuisine in which this recipe falls - this is our target variable (the test sample does not have this column);\n",
    "- a list object with ingredients (the recipe) - this will be the main source of explanatory variables in our classification problem.\n",
    "\n",
    "**Problem statement**: Predict the type of cuisine based on given data (ingredients). This is a classification task which requires text processing and analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "5929f64cbc6275c5ffbf5c06b268e9b4b2bf82e9"
   },
   "source": [
    "### * 3) Now let's explore a little bit more the target variable *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "fa495f582838edfddb51ec27524d37b2d6676157"
   },
   "outputs": [],
   "source": [
    "print(\"Number of cuisine categories: {}\".format(len(train_data.cuisine.unique())))\n",
    "train_data.cuisine.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "ff6b8449cce93b00ebf241f0b1e9b3a85da84fed"
   },
   "source": [
    "There are 20 different categories (cuisines) which we are going to predict. <br> \n",
    "**This means that the problem at hand is a multi-class classification (there are more than 2 categories to predict).** <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "28e5372da5d7cb819e99befbbd06e1a32f4f98f4"
   },
   "source": [
    "#### *Define a function for generating colours at random - it will be used for vizualizations in the analysis*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "b6499816e5c89695bceabca4bf9cbeed333d7a91"
   },
   "outputs": [],
   "source": [
    "def random_colours(number_of_colors):\n",
    "    '''\n",
    "    Simple function for random colours generation.\n",
    "    Input:\n",
    "        number_of_colors - integer value indicating the number of colours which are going to be generated.\n",
    "    Output:\n",
    "        Color in the following format: ['#E86DA4'] .\n",
    "    '''\n",
    "    colors = []\n",
    "    for i in range(number_of_colors):\n",
    "        colors.append(\"#\"+''.join([random.choice('0123456789ABCDEF') for j in range(6)]))\n",
    "    return colors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "641a7d847ef03b46c423264818c94c1d19eda55f"
   },
   "source": [
    "#### * Create a table giving information on the number of times each cuisine is represented in the training sample *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "cbd0f6db89fa92f9476da2915674817e4a46f86d"
   },
   "outputs": [],
   "source": [
    "trace = go.Table(\n",
    "                header=dict(values=['Cuisine','Number of recipes'],\n",
    "                fill = dict(color=['#EABEB0']), \n",
    "                align = ['left'] * 5),\n",
    "                cells=dict(values=[train_data.cuisine.value_counts().index,train_data.cuisine.value_counts()],\n",
    "               align = ['left'] * 5))\n",
    "\n",
    "layout = go.Layout(title='Number of recipes in each cuisine category',\n",
    "                   titlefont = dict(size = 20),\n",
    "                   width=500, height=650, \n",
    "                   paper_bgcolor =  'rgba(0,0,0,0)',\n",
    "                   plot_bgcolor = 'rgba(0,0,0,0)',\n",
    "                   autosize = False,\n",
    "                   margin=dict(l=30,r=30,b=1,t=50,pad=1),\n",
    "                   )\n",
    "data = [trace]\n",
    "fig = dict(data=data, layout=layout)\n",
    "iplot(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "11fab9569b51ac67610bfe6f7067da99ccddc1d3"
   },
   "source": [
    "#### * Create also a plot with label distribution *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "36377ca6cb92457599f4beb10b16d7dae8e3ecc4"
   },
   "outputs": [],
   "source": [
    "#  Label distribution in percents\n",
    "labelpercents = []\n",
    "for i in train_data.cuisine.value_counts():\n",
    "    percent = (i/sum(train_data.cuisine.value_counts()))*100\n",
    "    percent = \"%.2f\" % percent\n",
    "    percent = str(percent + '%')\n",
    "    labelpercents.append(percent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "beeda4324e7da2f62c4ad21afd18a84f0805ccdb"
   },
   "outputs": [],
   "source": [
    "trace = go.Bar(\n",
    "            x=train_data.cuisine.value_counts().values[::-1],\n",
    "            y= [i for i in train_data.cuisine.value_counts().index][::-1],\n",
    "            text =labelpercents[::-1],  textposition = 'outside', \n",
    "            orientation = 'h',marker = dict(color = random_colours(20)))\n",
    "layout = go.Layout(title='Number of recipes in each cuisine category',\n",
    "                   titlefont = dict(size = 25),\n",
    "                   width=1000, height=450, \n",
    "                   plot_bgcolor = 'rgba(0,0,0,0)',\n",
    "                   paper_bgcolor = 'rgba(255, 219, 227, 0.88)',\n",
    "                   margin=dict(l=75,r=110,b=50,t=60),\n",
    "                   )\n",
    "data = [trace]\n",
    "fig = dict(data=data, layout=layout)\n",
    "iplot(fig, filename='horizontal-bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "4c9b786c820726450a5d453f13cafcb4116a2042"
   },
   "source": [
    "From the table and the plot of label distribution, we observe that the most common category in our sample is the Italian cuisine, followed by the Mexican - they represent around 36% of our training sample. The least represented cuisines are the Irish, Jamaican, Russian and Brazilian - counting for only 6% of our training sample of recipes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "95168314b5845b434c33c4ad788f7ffcb0346eb1"
   },
   "source": [
    "### * 4) Let's take a closer look at the ingredients in our training sample *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "158f0b99191f888ae551a5305c40df523f88f938"
   },
   "outputs": [],
   "source": [
    "print('Maximum Number of Ingredients in a Dish: ',train_data['ingredients'].str.len().max())\n",
    "print('Minimum Number of Ingredients in a Dish: ',train_data['ingredients'].str.len().min())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "9ead81d6d2fe4592b46fc2d3dabbc4d413562f66"
   },
   "source": [
    "#### * Explore the distribution of recipe length *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "2a2a78012af20c299b981f10216d5515f0a10b11"
   },
   "outputs": [],
   "source": [
    "trace = go.Histogram(\n",
    "    x= train_data['ingredients'].str.len(),\n",
    "    xbins=dict(start=0,end=90,size=1),\n",
    "   marker=dict(color='#7CFDF0'),\n",
    "    opacity=0.75)\n",
    "data = [trace]\n",
    "layout = go.Layout(\n",
    "    title='Distribution of Recipe Length',\n",
    "    xaxis=dict(title='Number of ingredients'),\n",
    "    yaxis=dict(title='Count of recipes'),\n",
    "    bargap=0.1,\n",
    "    bargroupgap=0.2)\n",
    "\n",
    "fig = go.Figure(data=data, layout=layout)\n",
    "iplot(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "77cb6f515b3c30ff47b5ee67fa4fe696ddeabeb3"
   },
   "source": [
    "The distribution of recipe length is right-skewed as we can see from the histogram above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "494d7bc7730e16e15a5ba67589262eb9673ec999"
   },
   "source": [
    "#### * Take a closer look at the extremes *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "fc12d06769ac93c40321eb4c7cfd805d95101dec"
   },
   "outputs": [],
   "source": [
    "longrecipes = train_data[train_data['ingredients'].str.len() > 30]\n",
    "print(\"It seems that {} recipes consist of more than 30 ingredients!\".format(len(longrecipes)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "23b579cbe91a1aeae59340bb5d13d22f0fc5e551"
   },
   "outputs": [],
   "source": [
    "print(\"Explore the ingredients in the longest recipe in our training set:\" + \"\\n\")\n",
    "print(str(list(longrecipes[longrecipes['ingredients'].str.len() == 65].ingredients.values)) + \"\\n\")\n",
    "print(\"Cuisine: \" + str(list(longrecipes[longrecipes['ingredients'].str.len() == 65].cuisine)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "c0dffba19fa7aae3e4e7aa7c6eaaefdf722120fb"
   },
   "outputs": [],
   "source": [
    "shortrecipes = train_data[train_data['ingredients'].str.len() <= 2]\n",
    "print(\"It seems that {} recipes consist of less than or equal to 2 ingredients!\".format(len(shortrecipes)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "e046ace2cb738fa5f412d18e9a30c53436447f5d"
   },
   "outputs": [],
   "source": [
    "print(\"Explore the ingredients in the shortest recipes in our training set:\" + \"\\n\")\n",
    "print(list(train_data[train_data['ingredients'].str.len() == 1].ingredients.values))\n",
    "print(\"And there corresponding labels\" + \"\\n\")\n",
    "print(list(train_data[train_data['ingredients'].str.len() == 1].cuisine.values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "016bd336d84aa586fbcb7118059deab6ff380441"
   },
   "source": [
    "The longest recipe in our sample is part of the Italian cuisine. However, Italian cuisine is often associated with simple recipes - having not so many ingredients but still being extremely delicious. :)  <br><br>\n",
    "65 ingredients can be considered too many for any recipe. Making a quick google search on \"How many ingredients has the longest recipe in the world?\" does not give us a definite answer but one of the first results is a similar question posted on Reddit: <br>\n",
    "__( https://www.reddit.com/r/recipes/comments/4ir04r/question_most_complex_or_recipe_with_longest_list/ )__\n",
    " <br><br>\n",
    "Here we can find a recipe for Beef Wellington consisting of around 30 ingredients! Well, this is already a huge number but still 65 is beyond all that one can even imagine. So, our guess is that the case is more about wrong data in our sample rather than anything else.  \n",
    "\n",
    "It seems that most of the shortest recipes are part of the Asian cuisine - Indian, Japanese. Some of the recipes consist only of rice which to great extent is possible, but several of them (like water and butter only) look suspiciously wrong. It should be considered whether this data is wrong (for example, this is not the whole recipe due to some reasons like technical errors). <br><br>\n",
    "As far the Asian cuisine is considered - as a next step we are going to explore the distribution of recipe length in each cuisine which will shed light on the question whether short recipes are something typical for the Asian region."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "326b6a5aa000edbff4e553d7eff102d7798155f2"
   },
   "source": [
    "#### * Explore recipe length distribution in each cuisine *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "50bbdcbfafe3e4413f98afb5e181a3c6c665e534"
   },
   "outputs": [],
   "source": [
    "boxplotcolors = random_colours(21)\n",
    "labels = [i for i in train_data.cuisine.value_counts().index][::-1]\n",
    "data = []\n",
    "for i in range(20):\n",
    "    trace = go.Box(\n",
    "    y=train_data[train_data['cuisine'] == labels[i]]['ingredients'].str.len(), name = labels[i],\n",
    "    marker = dict(color = boxplotcolors[i]))\n",
    "    data.append(trace)\n",
    "layout = go.Layout(\n",
    "    title = \"Recipe Length Distribution by cuisine\"\n",
    ")\n",
    "\n",
    "fig = go.Figure(data=data,layout=layout)\n",
    "iplot(fig, filename = \"Box Plot Styling Outliers\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "bbb0f00436383b1cc309416739768b01c0cd0580"
   },
   "source": [
    "From the box plots of recipe length distributions, we can make several observations: <br>\n",
    "- the Moroccan cuisine seems to have the longest recipes on average compared to all the rest cuisines in our sample;\n",
    "- we observe the opposite phenomenon for the Irish, British, French and Southern_us cuisine;\n",
    "- there exist outliers in all cuisines (in some of them - many);\n",
    "- most of the Asian cuisines (Vietnamese, Thai, Indian) turn out to have larger recipes on average than most of the rest cuisines which means that our guess in [Take a closer look at the extremes](#-Take-a-closer-look-at-the-extremes-) about their length in not accurate; \n",
    "- recipes part of the European cuisine tend to be with average length or shorter compared to the rest of the sample."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "14cb400417288ff9d5e34567694b72e36dea2250"
   },
   "source": [
    "#### * Which are the most common ingredients in the whole training sample? How many unique ingredients can we find in the dataset? *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "c6a940815898625fdcdbe0aee9847e0d4d87c519"
   },
   "outputs": [],
   "source": [
    "allingredients = [] # this list stores all the ingredients in all recipes (with duplicates)\n",
    "for item in train_data['ingredients']:\n",
    "    for ingr in item:\n",
    "        allingredients.append(ingr) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "b48ef44d7ad0f36807b3b987461bd130c61b1073"
   },
   "outputs": [],
   "source": [
    "# Count how many times each ingredient occurs\n",
    "countingr = Counter()\n",
    "for ingr in allingredients:\n",
    "     countingr[ingr] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "2b5e26a7bb8d0f75cce7aa94ad4e84f18b749b37"
   },
   "outputs": [],
   "source": [
    "print(\"The most commonly used ingredients (with counts) are:\")\n",
    "print(\"\\n\")\n",
    "print(countingr.most_common(20))\n",
    "print(\"\\n\")\n",
    "print(\"The number of unique ingredients in our training sample is {}.\".format(len(countingr)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "1c051b230cadddf69c62aafe6add164e1b7b7455"
   },
   "outputs": [],
   "source": [
    "# Extract the first 20 most common ingredients in order to vizualize them for better understanding\n",
    "mostcommon = countingr.most_common(20)\n",
    "mostcommoningr = [i[0] for i in mostcommon]\n",
    "mostcommoningr_count = [i[1] for i in mostcommon]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "684f06055c67a1f2b55ad257fd9761f16c9ef9eb",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "trace = go.Bar(\n",
    "            x=mostcommoningr_count[::-1],\n",
    "            y= mostcommoningr[::-1],\n",
    "            orientation = 'h',marker = dict(color = random_colours(20),\n",
    "))\n",
    "layout = go.Layout(\n",
    "    xaxis = dict(title= 'Number of occurences in all recipes (training sample)', ),\n",
    "    yaxis = dict(title='Ingredient',),\n",
    "    title= '20 Most Common Ingredients', titlefont = dict(size = 20),\n",
    "    margin=dict(l=150,r=10,b=60,t=60,pad=5),\n",
    "    width=800, height=500, \n",
    ")\n",
    "data = [trace]\n",
    "fig = go.Figure(data=data, layout=layout)\n",
    "iplot(fig, filename='horizontal-bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "a1d324d231859c12ebe55dd9158b05efea46c02c"
   },
   "source": [
    "ü•ï It seems that salt is the most commonly used ingredient which is not surprising at all! We also find water, onions, garlic and olive oil - not so surprising also. :) <br> \n",
    " Salt is such a common ingredient that we expect it to have poor predictive power in recognizing the type of cuisine."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "97c2ed3e629d059f9e6a4456bded4a3cbd2bd1a2"
   },
   "source": [
    "#### * Explore how many different ingredients can be found in each cuisine *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "8412420fdd41e5e73129abbfcc1df30b9bc2664f"
   },
   "outputs": [],
   "source": [
    "# Define a function that returns how many different ingredients can be found in all recipes part of a given cuisine\n",
    "def findnumingr(cuisine):\n",
    "    '''\n",
    "    Input:\n",
    "        cuisine - cuisine category (ex. greek,souther_us etc.)\n",
    "    Output:\n",
    "        The number of unique ingredients used in all recipes part of the given cuisine. \n",
    "    '''\n",
    "    listofinrg = []\n",
    "    for item in train_data[train_data['cuisine'] == cuisine]['ingredients']:\n",
    "        for ingr in item:\n",
    "            listofinrg.append(ingr)\n",
    "    result = (cuisine,len(list(set(listofinrg))))         \n",
    "    return result "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "7e773e1cee2e96c11d8c5da7cdb064a4e4522b1d"
   },
   "outputs": [],
   "source": [
    "cuisineallingr = []\n",
    "for i in labels:\n",
    "    cuisineallingr.append(findnumingr(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "878fc129b44c6609dc765522df15cbe7969ad932"
   },
   "outputs": [],
   "source": [
    "# Vizualize the results\n",
    "trace = go.Bar(\n",
    "            x=[i[1] for i in cuisineallingr],\n",
    "            y= [i[0] for i in cuisineallingr],\n",
    "            orientation = 'h',marker = dict(color = random_colours(20),\n",
    "))\n",
    "layout = go.Layout(\n",
    "    xaxis = dict(title= 'Count of different ingredients', ),\n",
    "    yaxis = dict(title='Cuisine',),\n",
    "    title= 'Number of all the different ingredients used in a given cuisine', titlefont = dict(size = 20),\n",
    "    margin=dict(l=100,r=10,b=60,t=60),\n",
    "    width=800, height=500, \n",
    ")\n",
    "data = [trace]\n",
    "fig = go.Figure(data=data, layout=layout)\n",
    "iplot(fig, filename='horizontal-bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "284c38da16d9b7d279a6d36790cf385d2bb3cead"
   },
   "source": [
    "From the above bar chart, we can see that it is not necessary that cuisines with more instances in the training sample should be associated with more ingredients representing them. It turns out that the French cuisine which is 6,65% of the training sample has more variability in ingredients than the Indian cuisine (this observation is unexpected since Indians use many spices in their recipes - __[Wiki-Indian cuisine](https://en.wikipedia.org/wiki/Indian_cuisine)__ ).   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "9e7355becf6e4654bd8556294e1bdb6679098755"
   },
   "source": [
    "#### *Explore which ingredients occur **only in one cuisine** (ingredients specific to the cuisine) *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "a01ea4b4b9d28ceb5bb23959c84f71ec9d68ff0f"
   },
   "outputs": [],
   "source": [
    "allingredients = list(set(allingredients)) # list containing all unique ingredients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "440cde2ff0a0157f11bdbff72f0b2f26a8944b08"
   },
   "outputs": [],
   "source": [
    "# Define a function that returns a dataframe with top unique ingredients in a given cuisine \n",
    "def cuisine_unique(cuisine,numingr, allingredients):\n",
    "    '''\n",
    "    Input:\n",
    "        cuisine - cuisine category (ex. 'brazilian');\n",
    "        numingr - how many specific ingredients do you want to see in the final result; \n",
    "        allingredients - list containing all unique ingredients in the whole sample.\n",
    "    \n",
    "    Output: \n",
    "        dataframe giving information about the name of the specific ingredient and how many times it occurs in the chosen cuisine (in descending order based on their counts)..\n",
    "\n",
    "    '''\n",
    "    allother = []\n",
    "    for item in train_data[train_data.cuisine != cuisine]['ingredients']:\n",
    "        for ingr in item:\n",
    "            allother .append(ingr)\n",
    "    allother  = list(set(allother ))\n",
    "    \n",
    "    specificnonly = [x for x in allingredients if x not in allother]\n",
    "    \n",
    "    mycounter = Counter()\n",
    "    \n",
    "    for item in train_data[train_data.cuisine == cuisine]['ingredients']:\n",
    "        for ingr in item:\n",
    "            mycounter[ingr] += 1\n",
    "    keep = list(specificnonly)\n",
    "    \n",
    "    for word in list(mycounter):\n",
    "        if word not in keep:\n",
    "            del mycounter[word]\n",
    "    \n",
    "    cuisinespec = pd.DataFrame(mycounter.most_common(numingr), columns = ['ingredient','count'])\n",
    "    \n",
    "    return cuisinespec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "3ebd3c3cfe102bb7e3954da500a7043f3f361a3b"
   },
   "outputs": [],
   "source": [
    "cuisinespec= cuisine_unique('mexican', 10, allingredients)\n",
    "print(\"The top 10 unique ingredients in Mexican cuisine are:\")\n",
    "cuisinespec "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "6e840f216982b68211fc0681397ec90584543c6a"
   },
   "source": [
    "Mmmmmm tacos and tortillas...Yummy! üåÆ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "172c49be26e0db4370d880e37761475e35c3b832"
   },
   "source": [
    "#### *Now let's make some vizualizations of our findings about the \"special\" ingredients *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "fe501754bfd3f1565ff1a37cc3dc0998f47e25f8"
   },
   "outputs": [],
   "source": [
    "# Vizualization of specific ingredients in the first 10 cuisines\n",
    "labels = [i for i in train_data.cuisine.value_counts().index][0:10]\n",
    "totalPlot = 10\n",
    "y = [[item]*2 for item in range(1,10)]\n",
    "y = list(chain.from_iterable(y))\n",
    "z = [1,2]*int((totalPlot/2))\n",
    "\n",
    "fig = tools.make_subplots(rows= 5, cols=2, subplot_titles= labels, specs = [[{}, {}],[{}, {}],[{}, {}],[{}, {}],[{}, {}]],  horizontal_spacing = 0.20)\n",
    "traces = []\n",
    "for i,e in enumerate(labels): \n",
    "    cuisinespec= cuisine_unique(e, 5, allingredients)\n",
    "    trace = go.Bar(\n",
    "            x= cuisinespec['count'].values[::-1],\n",
    "            y=  cuisinespec['ingredient'].values[::-1],\n",
    "            orientation = 'h',marker = dict(color = random_colours(5),))\n",
    "    traces.append(trace)\n",
    "\n",
    "for t,y,z in zip(traces,y,z):\n",
    "    fig.append_trace(t, y,z)\n",
    "\n",
    "    fig['layout'].update(height=800, width=840,\n",
    "    margin=dict(l=265,r=5,b=40,t=90,pad=5), showlegend=False, title='Ingredients used only in one cuisine')\n",
    "\n",
    "iplot(fig, filename='horizontal-bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "2aa242335e2cd03c3ca5eb16cfd48618209a82c8"
   },
   "outputs": [],
   "source": [
    "# Vizualization of specific ingredients in the second 10 cuisines\n",
    "labels = [i for i in train_data.cuisine.value_counts().index][10:20]\n",
    "totalPlot = 10\n",
    "y = [[item]*2 for item in range(1,10)]\n",
    "y = list(chain.from_iterable(y))\n",
    "z = [1,2]*int((totalPlot/2))\n",
    "\n",
    "fig = tools.make_subplots(rows= 5, cols=2, subplot_titles= labels, specs = [[{}, {}],[{}, {}],[{}, {}],[{}, {}],[{}, {}]],  horizontal_spacing = 0.20)\n",
    "traces = []\n",
    "for i,e in enumerate(labels): \n",
    "    cuisinespec= cuisine_unique(e, 5, allingredients)\n",
    "    trace = go.Bar(\n",
    "            x= cuisinespec['count'].values[::-1],\n",
    "            y=  cuisinespec['ingredient'].values[::-1],\n",
    "            orientation = 'h',marker = dict(color = random_colours(5),))\n",
    "    traces.append(trace)\n",
    "\n",
    "for t,y,z in zip(traces,y,z):\n",
    "    fig.append_trace(t, y,z)\n",
    "\n",
    "    fig['layout'].update(height=800, width=840,\n",
    "    margin=dict(l=170,r=5,b=40,t=90,pad=5), showlegend=False, title='Ingredient used only in one cuisine')\n",
    "\n",
    "iplot(fig, filename='horizontal-bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "1c327484a20a4b861c9bcadf517aa44a3dbdf926"
   },
   "source": [
    "üçõ From the two vizualizations above we can make several observations: <br>\n",
    "- the Mexican cuisine is the only one where we find that the unique ingredients are also found in many recipes part of the cuisine in question. The refried beans are found more than 200 times in Mexican recipes (250 out of 6438 recipes ~ 4% of all Mexican recipes). This finding means that the 'refried beans' and 'taco' (or derivatives of those) ingredients are expected to be strong predictors of Mexican cuisine. On the next step of the analysis we will try to support this observation by using Tf-Idf representation of our training sample in an attempt to find the most important ingredients in a cuisine.\n",
    "- the above-mentioned observation is also valid for the:\n",
    "    - the Italian gnocchi -   __[Wikipedia - Gnocchi](https://en.wikipedia.org/wiki/Gnocchi)__;\n",
    "    - Brazilian cuisine with its traditional cachaca which is the most popular spirit among distilled alcoholic beverage in Brazil (or at least according to __[Wikipedia - Cachaca](https://en.wikipedia.org/wiki/Cacha%C3%A7a)__).\n",
    "    - Indian fenugreek - in our sample it is found only in the Indian cuisine which is surprising since it can be found in the whole Asian region __[Wikipedia - Fenugreek](https://en.wikipedia.org/wiki/Fenugreek)__) and also because in my home-country (Bulgaria) we also use it a lot which means that it is not specific only to the Asian region. :)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "d27a1c348a3d5888b67baade2135f38d2da400d3"
   },
   "source": [
    "#### *Find the most important ingredients in each cuisine using Tf-Idf transformation*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "655d87c682609750a49b5ca3cbb89f43c971c242"
   },
   "source": [
    "Tf-Idf measure will simply point out which are the features (words) that are important for a given cuisine. To put it simply - these will be ingredients that are frequently used in the recipes belonging to that cuisine and at the same time not so frequently used in the whole sample of recipes.  <br><br> \n",
    "Higher tf-idf score means higher importance of the word for the given cuisine and the opposite (for more information on the measure and how it is calculated:__[Tf-Idf](https://en.wikipedia.org/wiki/Tf%E2%80%93idf)__ ). <br><br>\n",
    "The result of the Tf-Idf transformation of our dataset is a matrix of tf-idf scores with one row per recipe and as many columns as there are different ingredients in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "463260547ea8e5032085fa61572b7c53e9a3ce7f"
   },
   "outputs": [],
   "source": [
    "# Prepare the data \n",
    "features = [] # list of list containg the recipes\n",
    "for item in train_data['ingredients']:\n",
    "    features.append(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "909ef07a09fc90a3baeb56fd3607c42597b5de97"
   },
   "outputs": [],
   "source": [
    "ingredients = [] # this list stores all the ingredients in all recipes (with duplicates)\n",
    "for item in train_data['ingredients']:\n",
    "    for ingr in item:\n",
    "        ingredients.append(ingr) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "2d5ac0b04d8b56508e5f8397ccd644b0e27d642c"
   },
   "outputs": [],
   "source": [
    "len(features) # 39774 recipes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "78db2b4234a53b9ed6cee41f98cae3e4eabf916a"
   },
   "outputs": [],
   "source": [
    "# Fit the TfidfVectorizer to data\n",
    "tfidf = TfidfVectorizer(vocabulary= list(set([str(i).lower() for i in ingredients])), max_df=0.99, norm='l2', ngram_range=(1, 4))\n",
    "X_tr = tfidf.fit_transform([str(i) for i in features]) # X_tr - matrix of tf-idf scores\n",
    "feature_names = tfidf.get_feature_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "14aa640cf1f45c7eb981ace127c57b26b01a0159"
   },
   "source": [
    "*Important Note: For the Tf-Idf representation we are using as vocabulary the ingredients as they are given in the data - no unigrams or bigrams are extracted at this stage. Also bear in mind that the data is not processed/cleaned.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "ee464cd21a9cbae3ac9a419bf96eece1776537a8"
   },
   "outputs": [],
   "source": [
    "# Define a function for finding the most important features in a given cuisine according to Tf-Idf measure \n",
    "def top_feats_by_class(trainsample,target,featurenames, min_tfidf=0.1, top_n=10):\n",
    "    ''' \n",
    "     Input:\n",
    "         trainsample - the tf-idf transformed training sample;\n",
    "         target - the target variable;\n",
    "         featurenames - array mapping from feature integer indices (position in the dataset) to feature name (ingredient in our case) in the Tf-Idf transformed dataset; \n",
    "         min_tfidf - features having tf-idf value below the min_tfidf will be excluded ;\n",
    "         top_n - how many important features to show.\n",
    "     Output:\n",
    "          Returns a list of dataframe objects, where each dataframe holds top_n features and their mean tfidf value\n",
    "         calculated across documents (recipes) with the same class label (cuisine). \n",
    "     '''\n",
    "    dfs = []\n",
    "    labels = np.unique(target)\n",
    "    \n",
    "    for label in labels:\n",
    "        \n",
    "        ids = np.where(target==label)\n",
    "        D = trainsample[ids].toarray()\n",
    "        D[D < min_tfidf] = 0\n",
    "        tfidf_means = np.nanmean(D, axis=0)\n",
    "        \n",
    "        topn_ids = np.argsort(tfidf_means)[::-1][:top_n] #  Get top n tfidf values\n",
    "        top_feats = [(featurenames[i], tfidf_means[i]) for i in topn_ids] # find their corresponding feature names\n",
    "        df = pd.DataFrame(top_feats)\n",
    "        df.columns = ['feature', 'tfidf']\n",
    "        \n",
    "        df['cuisine'] = label\n",
    "        dfs.append(df)\n",
    "        \n",
    "    return dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "6583e2f23fd4e36bbbe5190479d2757e8cbe4569"
   },
   "outputs": [],
   "source": [
    "# Extract the target variable\n",
    "target = train_data['cuisine']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "f9eb46b29cfe0c071ddcfce96a4cd47b16f46188"
   },
   "outputs": [],
   "source": [
    "result_tfidf = top_feats_by_class(X_tr, target, feature_names, min_tfidf=0.1, top_n=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "f8da9c4260409cb82e61bf7ea60d8faab7d01343"
   },
   "source": [
    "#### *Vizualizations of Important Features according to Tf-Idf measure*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "fb1e7d203c1826032652c519190bda7f6af14435"
   },
   "outputs": [],
   "source": [
    "# Exctract labels from the resulting dataframe\n",
    "labels = []\n",
    "for i, e in enumerate(result_tfidf):\n",
    "    labels.append(result_tfidf[i].cuisine[0])\n",
    "\n",
    "# Set the plot\n",
    "totalPlot = 10\n",
    "y = [[item]*2 for item in range(1,10)]\n",
    "y = list(chain.from_iterable(y))\n",
    "z = [1,2]*int((totalPlot/2))\n",
    "\n",
    "fig = tools.make_subplots(rows= 5, cols=2, subplot_titles= labels[0:10], specs = [[{}, {}],[{}, {}],[{}, {}],[{}, {}],[{}, {}]],  horizontal_spacing = 0.20)\n",
    "traces = []\n",
    "for index,element in enumerate(result_tfidf[0:10]): \n",
    "    trace = go.Bar(\n",
    "            x= result_tfidf[index].tfidf[::-1],\n",
    "            y= result_tfidf[index].feature[::-1],\n",
    "            orientation = 'h',marker = dict(color = random_colours(5),))\n",
    "    traces.append(trace)\n",
    "\n",
    "for t,y,z in zip(traces,y,z):\n",
    "    fig.append_trace(t, y,z)\n",
    "\n",
    "    fig['layout'].update(height=800, width=840,\n",
    "    margin=dict(l=110,r=5,b=40,t=90,pad=5), showlegend=False, title='Feature Importance based on Tf-Idf measure')\n",
    "\n",
    "iplot(fig, filename='horizontal-bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "4a00c728b9df0d7721ed0588293d6f29ed30f6d8"
   },
   "outputs": [],
   "source": [
    "# Set the plot\n",
    "totalPlot = 10\n",
    "y = [[item]*2 for item in range(1,10)]\n",
    "y = list(chain.from_iterable(y))\n",
    "z = [1,2]*int((totalPlot/2))\n",
    "\n",
    "fig = tools.make_subplots(rows= 5, cols=2, subplot_titles= labels[10:20], specs = [[{}, {}],[{}, {}],[{}, {}],[{}, {}],[{}, {}]],  horizontal_spacing = 0.20)\n",
    "traces = []\n",
    "for index,element in enumerate(result_tfidf[10:20]): \n",
    "    trace = go.Bar(\n",
    "            x= result_tfidf[10:20][index].tfidf[::-1],\n",
    "            y= result_tfidf[10:20][index].feature[::-1],\n",
    "            orientation = 'h',marker = dict(color = random_colours(5),))\n",
    "    traces.append(trace)\n",
    "\n",
    "for t,y,z in zip(traces,y,z):\n",
    "    fig.append_trace(t, y,z)\n",
    "\n",
    "    fig['layout'].update(height=800, width=840,\n",
    "    margin=dict(l=100,r=5,b=40,t=90,pad=5), showlegend=False, title='Feature Importance based on Tf-Idf measure')\n",
    "\n",
    "iplot(fig, filename='horizontal-bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "b272c7809a6d2a6b8006bf185e7c47b813fbc80f"
   },
   "source": [
    "From the vizualizations above we can make the following observations: <br>\n",
    "- several of our assumptions in [this section of the analysis](#Now-let's-make-some-vizualizations-of-our-findings-about-the-special-ingredients-) were accurate - cachaca is major ingredient in Brazilian recipes and tortillas are important in Mexican cuisine.\n",
    "- some of the important words appear in several cuisines, BUT still this observation holds true only if the cuisines are in the same region:\n",
    "    - In Asian cuisines we find that fish, sauce, soy and sesame are all with higher tf-idf values;\n",
    "    - butter, sugar, eggs and flour are found in several European cuisines;\n",
    "    - Greek, Spanish and Italian cuisines all share olive oil and cheese.\n",
    "- another observation we can make is that different spices (rather than food like fruits, vegetables, fish or meat) dominate the Moroccan, Indian and Jamaican cuisines."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "0087bd8bfa9fa3cbd79a2bfb2998a934f5a2cb86"
   },
   "source": [
    "  # II.What's Cooking? - Text Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "00961d449239a10cc2ef1dfb41bf306c76825e5f"
   },
   "source": [
    "We will proceed the analysis by performing some simple data processing. The aim is to prepare the data for model development."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "34485d250391a9d37cad41a1d175a6e3f74e905b"
   },
   "source": [
    "###  * 1) Prepare the train and test samples for model development*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "6306134afa999013052f8308fef68d7e56b2b284"
   },
   "outputs": [],
   "source": [
    "# Train sample \n",
    "print(\"How training data looks like at this stage (example of one recipe):\")\n",
    "print(str(features[0]) + '\\n' )\n",
    "print(\"Number of instances: \"+ str(len(features)) + '\\n')\n",
    "print(\"And the target variable:\")\n",
    "print(target[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "26a1c07a22573e7f4d2bc34bc01bbf97b0ad9f43"
   },
   "outputs": [],
   "source": [
    "# Test Sample - only features - the target variable is not provided.\n",
    "features_test = [] # list of lists containg the recipes\n",
    "for item in test_data['ingredients']:\n",
    "    features_test.append(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "ddad4bb5d933879c59e62da87264c3d3e713394c"
   },
   "outputs": [],
   "source": [
    "print(\"How test data looks like at this stage (example of one recipe):\")\n",
    "print(str(features_test[0]) + '\\n')\n",
    "print(\"Number of instances: \"+ str(len(features_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "db13e7ed35481fa83050b87b5c5bd0b5f7f67661"
   },
   "outputs": [],
   "source": [
    "# Both train and test samples are processed in the exact same way\n",
    "# Train\n",
    "features_processed= [] # here we will store the preprocessed training features\n",
    "for item in features:\n",
    "    newitem = []\n",
    "    for ingr in item:\n",
    "        ingr.lower() # Case Normalization - convert all to lower case \n",
    "        ingr = re.sub(\"[^a-zA-Z]\",\" \",ingr) # Remove punctuation, digits or special characters \n",
    "        ingr = re.sub((r'\\b(oz|ounc|ounce|pound|lb|inch|inches|kg|to)\\b'), ' ', ingr) # Remove different units  \n",
    "        newitem.append(ingr)\n",
    "    features_processed.append(newitem)\n",
    "\n",
    "# Test \n",
    "features_test_processed= [] \n",
    "for item in features_test:\n",
    "    newitem = []\n",
    "    for ingr in item:\n",
    "        ingr.lower() \n",
    "        ingr = re.sub(\"[^a-zA-Z]\",\" \",ingr)\n",
    "        ingr = re.sub((r'\\b(oz|ounc|ounce|pound|lb|inch|inches|kg|to)\\b'), ' ', ingr) \n",
    "        newitem.append(ingr)\n",
    "    features_test_processed.append(newitem) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "7bcd72b5391999bba2df81a76f57330111926996"
   },
   "outputs": [],
   "source": [
    "# Check for empty instances in train and test samples after processing before proceeding to next stage of the analysis    \n",
    "count_m = []    \n",
    "for recipe in features_processed:\n",
    "    if not recipe:\n",
    "        count_m.append([recipe])\n",
    "    else: pass\n",
    "print(\"Empty instances in the preprocessed training sample: \" + str(len(count_m)))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "0f39a01be0895b05fefefc4b5ed7520a4bd2a960"
   },
   "outputs": [],
   "source": [
    "count_m = []    \n",
    "for recipe in features_test_processed:\n",
    "    if not recipe:\n",
    "        count_m.append([recipe])\n",
    "    else: pass\n",
    "print(\"Empty instances in the preprocessed test sample: \" + str(len(count_m)))    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "ab55f0cfc2193ee7c234deb1bb15696e9d3bed4a"
   },
   "source": [
    "Now the data is prepared for building a prediction model based on ingredients. At this step of the analysis we made some simple but important transformations on the data:\n",
    "- Case normalization - all words are  converted to lower case;\n",
    "- Removal of punctuation, digits or special characters - they are not considered as informative and correlated with the problem;\n",
    "- Removal of different units measuring the ingredients - they can also be considered as not so related to the problem at hand and therefore can be excluded from further analysis. <br>\n",
    "\n",
    "Performing this simple manipulation on data can give us confidence that a significant amount of 'noise' in our data is removed which is likely to lead to better results during the data modeling stage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "2c645b4e09bcac833c715ef1632b6cfd7c72824e"
   },
   "source": [
    "  # III. What's Cooking? - Feature Engineering & Data Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "a61aea846372e910b4fd0e495c0a5dfe4ce12315"
   },
   "source": [
    "###  * 1) Feature engineering*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "4bf4f2768d5c5466be7e64588c0fcfe5162529af"
   },
   "outputs": [],
   "source": [
    "# Binary representation of the training set will be employed\n",
    "vectorizer = CountVectorizer(analyzer = \"word\",\n",
    "                             ngram_range = (1,1), # unigrams\n",
    "                             binary = True, #  (the default is counts)\n",
    "                             tokenizer = None,    \n",
    "                             preprocessor = None, \n",
    "                             stop_words = None,  \n",
    "                             max_df = 0.99) # any word appearing in more than 99% of the sample will be discarded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "a8b32154e2545935d184c230cefa3b9b058f934a"
   },
   "outputs": [],
   "source": [
    "# Fit the vectorizer on the training data and transform the test sample\n",
    "train_X = vectorizer.fit_transform([str(i) for i in features_processed])\n",
    "test_X =  vectorizer.transform([str(i) for i in features_test_processed])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "b1fe459dd494d3b6c30d17c7badcf4c427505f49"
   },
   "source": [
    "**During the feature engineering stage we transform the textual data into more suitable format for performing mathematical operations and statistical learning techniques. In other words - we turn text into numbers.**\n",
    "\n",
    "We choose to use binary representation which is very simple to understand and implement. Also for simplicity we choose to use only unigrams for building the prediction model. This means that in model development will be included features consisting of single words only. This can be considered as a good baseline and starting point for further analysis. <br> Finally, we exclude words appearing in more than 99% of our training instances because they can't be considered as good differentiators of data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
