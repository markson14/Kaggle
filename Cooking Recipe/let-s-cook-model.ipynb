{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "source": [
    "# Let's cook model\n",
    "\n",
    "Let's combine what we've found so far.\n",
    "\n",
    "- [What are ingredients?](https://www.kaggle.com/rejasupotaro/what-are-ingredients) (Preprocessing & Feature extraction)\n",
    "- [Representations for ingredients](https://www.kaggle.com/rejasupotaro/representations-for-ingredients)\n",
    "\n",
    "Steps are below.\n",
    "\n",
    "1. Load dataset\n",
    "2. Remove outliers\n",
    "3. Preprocess\n",
    "4. Create model\n",
    "5. Check local CV\n",
    "6. Train model\n",
    "7. Check predicted values\n",
    "8. Make submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "import unidecode\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import make_pipeline, make_union\n",
    "from sklearn.preprocessing import FunctionTransformer, LabelEncoder\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "0e71a483cf5522143e6accc7f89a246dd2b84eac"
   },
   "source": [
    "## 1. Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_uuid": "68cf27ffa9750f359ebeae70edf914a389697444"
   },
   "outputs": [],
   "source": [
    "train = pd.read_json('train.json')\n",
    "test = pd.read_json('test.json')\n",
    "train1 = pd.read_json('cooking_train.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = [train, train1]\n",
    "train = pd.concat(frames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "fa9226059c24efcaa31d78667aaaa3b9f1644cd8"
   },
   "source": [
    "## 2. Remove outliers\n",
    "\n",
    "I saw weird recipes in the dataset .\n",
    "\n",
    "- water => Japanese\n",
    "- butter => Indian\n",
    "- butter => French\n",
    "\n",
    "Let's filter such single-ingredient recipes and see how it goes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_uuid": "048849307c7233eb2bea8ea4f289f49e02a517b8"
   },
   "outputs": [],
   "source": [
    "train['num_ingredients'] = train['ingredients'].apply(lambda x: len(x))\n",
    "train = train[train['num_ingredients'] > 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "7cf37767200798f40405dcfecf862f9eabe2a89b"
   },
   "source": [
    "## 3. Preprocess\n",
    "\n",
    "Currently, the preprocess is like below.\n",
    "\n",
    "- convert to lowercase\n",
    "- remove hyphen\n",
    "- remove numbers\n",
    "- remove words which consist of less than 2 characters\n",
    "- lemmatize\n",
    "\n",
    "This process can be better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_uuid": "11919def05f043269b6ab823636468f29ae1651f"
   },
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "def preprocess(ingredients):\n",
    "    ingredients_text = ' '.join(ingredients)\n",
    "    ingredients_text = ingredients_text.lower()\n",
    "    ingredients_text = ingredients_text.replace('-', ' ')\n",
    "    words = []\n",
    "    for word in ingredients_text.split():\n",
    "        if re.findall('[0-9]', word): continue\n",
    "        if len(word) <= 2: continue\n",
    "        if '’' in word: continue\n",
    "        word = lemmatizer.lemmatize(word)\n",
    "        if len(word) > 0: words.append(word)\n",
    "    return ' '.join(words)\n",
    "\n",
    "for ingredient, expected in [\n",
    "    ('Eggs', 'egg'),\n",
    "    ('all-purpose flour', 'all purpose flour'),\n",
    "    ('purée', 'purée'),\n",
    "    ('1% low-fat milk', 'low fat milk'),\n",
    "    ('half & half', 'half half'),\n",
    "    ('safetida (powder)', 'safetida (powder)')\n",
    "]:\n",
    "    actual = preprocess([ingredient])\n",
    "    assert actual == expected, f'\"{expected}\" is excpected but got \"{actual}\"'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_uuid": "9004a952dab3fdbbec867ba73c424b8d6da9aa99"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 69732/69732 [00:15<00:00, 4562.08it/s]\n",
      "100%|██████████| 9944/9944 [00:02<00:00, 4700.89it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cuisine</th>\n",
       "      <th>id</th>\n",
       "      <th>ingredients</th>\n",
       "      <th>num_ingredients</th>\n",
       "      <th>x</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>greek</td>\n",
       "      <td>10259</td>\n",
       "      <td>[romaine lettuce, black olives, grape tomatoes...</td>\n",
       "      <td>9</td>\n",
       "      <td>romaine lettuce black olive grape tomato garli...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>southern_us</td>\n",
       "      <td>25693</td>\n",
       "      <td>[plain flour, ground pepper, salt, tomatoes, g...</td>\n",
       "      <td>11</td>\n",
       "      <td>plain flour ground pepper salt tomato ground b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>filipino</td>\n",
       "      <td>20130</td>\n",
       "      <td>[eggs, pepper, salt, mayonaise, cooking oil, g...</td>\n",
       "      <td>12</td>\n",
       "      <td>egg pepper salt mayonaise cooking oil green ch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>indian</td>\n",
       "      <td>22213</td>\n",
       "      <td>[water, vegetable oil, wheat, salt]</td>\n",
       "      <td>4</td>\n",
       "      <td>water vegetable oil wheat salt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>indian</td>\n",
       "      <td>13162</td>\n",
       "      <td>[black pepper, shallots, cornflour, cayenne pe...</td>\n",
       "      <td>20</td>\n",
       "      <td>black pepper shallot cornflour cayenne pepper ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       cuisine     id                                        ingredients  \\\n",
       "0        greek  10259  [romaine lettuce, black olives, grape tomatoes...   \n",
       "1  southern_us  25693  [plain flour, ground pepper, salt, tomatoes, g...   \n",
       "2     filipino  20130  [eggs, pepper, salt, mayonaise, cooking oil, g...   \n",
       "3       indian  22213                [water, vegetable oil, wheat, salt]   \n",
       "4       indian  13162  [black pepper, shallots, cornflour, cayenne pe...   \n",
       "\n",
       "   num_ingredients                                                  x  \n",
       "0                9  romaine lettuce black olive grape tomato garli...  \n",
       "1               11  plain flour ground pepper salt tomato ground b...  \n",
       "2               12  egg pepper salt mayonaise cooking oil green ch...  \n",
       "3                4                     water vegetable oil wheat salt  \n",
       "4               20  black pepper shallot cornflour cayenne pepper ...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['x'] = train['ingredients'].progress_apply(lambda ingredients: preprocess(ingredients))\n",
    "test['x'] = test['ingredients'].progress_apply(lambda ingredients: preprocess(ingredients))\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "55996a4fb96f4e25b43e63ba32b3fc903f19d0f6"
   },
   "source": [
    "I need to tune the parameters of TfidfVectorizer later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_uuid": "c363f1fa47d92507bc4ea8cfee0736dc4e567769"
   },
   "outputs": [],
   "source": [
    "vectorizer = make_pipeline(\n",
    "    TfidfVectorizer(sublinear_tf=True),\n",
    "    FunctionTransformer(lambda x: x.astype('float16'), validate=False)\n",
    ")\n",
    "\n",
    "x_train = vectorizer.fit_transform(train['x'].values)\n",
    "x_train.sort_indices()\n",
    "x_test = vectorizer.transform(test['x'].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "751a78d993338727709d7d3f763b87fcb87a6131"
   },
   "source": [
    "Encode cuisines to numeric values using LabelEncoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_uuid": "6d98153f94dbe4129d51040062ce3127ae6aeef5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'brazilian': 0,\n",
       " 'british': 1,\n",
       " 'cajun_creole': 2,\n",
       " 'chinese': 3,\n",
       " 'filipino': 4,\n",
       " 'french': 5,\n",
       " 'greek': 6,\n",
       " 'indian': 7,\n",
       " 'irish': 8,\n",
       " 'italian': 9,\n",
       " 'jamaican': 10,\n",
       " 'japanese': 11,\n",
       " 'korean': 12,\n",
       " 'mexican': 13,\n",
       " 'moroccan': 14,\n",
       " 'russian': 15,\n",
       " 'southern_us': 16,\n",
       " 'spanish': 17,\n",
       " 'thai': 18,\n",
       " 'vietnamese': 19}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "y_train = label_encoder.fit_transform(train['cuisine'].values)\n",
    "dict(zip(label_encoder.classes_, label_encoder.transform(label_encoder.classes_)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "032ff9e67221ccceeff64075b56d3b707558d1c1"
   },
   "source": [
    "## 4. Create model\n",
    "\n",
    "I've tried LogisticRegression, GaussianProcessClassifier, GradientBoostingClassifier, MLPClassifier, LGBMClassifier, SGDClassifier, Keras but SVC works better so far.\n",
    "\n",
    "I need to take a look at models and the parameters more closely."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_uuid": "356b6fc5fff859f83e8a1e351d762ff87f31b935"
   },
   "outputs": [],
   "source": [
    "estimator = SVC(\n",
    "    C=50,\n",
    "    kernel='rbf',\n",
    "    gamma=1.4,\n",
    "    coef0=1,\n",
    "    cache_size=500,\n",
    ")\n",
    "classifier = OneVsRestClassifier(estimator, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "cfbec2ac72ebecf900ffcf6524562785422aa581"
   },
   "source": [
    "## 5. Train model\n",
    "\n",
    "If I become to be confident in the model, I train it with the whole train data for submission."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_uuid": "02d2775c4878fd70a6345c1605ea7e3abe9cb9cb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 37min 5s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "OneVsRestClassifier(estimator=SVC(C=50, cache_size=500, class_weight=None, coef0=1,\n",
       "  decision_function_shape='ovr', degree=3, gamma=1.4, kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False),\n",
       "          n_jobs=-1)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "classifier.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "695d33e429e0ab905e2609752a5e3e29ce09d458"
   },
   "source": [
    "## 6. Check predicted values\n",
    "\n",
    "Check if the model fitted enough."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "_uuid": "47de4da03da0f0b817e99095dcb7be8974e531ee"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\user\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "c:\\users\\user\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy score on train data: 0.9996701657775483\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f1-score</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>avg / total</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>69732.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>brazilian</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>819.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>british</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1404.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chinese</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4687.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>greek</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2071.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>irish</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1165.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>italian</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13730.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mexican</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11320.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>russian</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>849.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>southern_us</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7598.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spanish</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1727.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cajun_creole</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2706.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>filipino</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1319.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>french</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4625.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>indian</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5277.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>jamaican</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>930.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>japanese</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2493.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>korean</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1446.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>moroccan</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1426.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>thai</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2697.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vietnamese</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1443.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              f1-score  precision  recall  support\n",
       " avg / total       1.0        1.0     1.0  69732.0\n",
       " brazilian         1.0        1.0     1.0    819.0\n",
       " british           1.0        1.0     1.0   1404.0\n",
       " chinese           1.0        1.0     1.0   4687.0\n",
       " greek             1.0        1.0     1.0   2071.0\n",
       " irish             1.0        1.0     1.0   1165.0\n",
       " italian           1.0        1.0     1.0  13730.0\n",
       " mexican           1.0        1.0     1.0  11320.0\n",
       " russian           1.0        1.0     1.0    849.0\n",
       " southern_us       1.0        1.0     1.0   7598.0\n",
       " spanish           1.0        1.0     1.0   1727.0\n",
       "cajun_creole       1.0        1.0     1.0   2706.0\n",
       "filipino           1.0        1.0     1.0   1319.0\n",
       "french             1.0        1.0     1.0   4625.0\n",
       "indian             1.0        1.0     1.0   5277.0\n",
       "jamaican           1.0        1.0     1.0    930.0\n",
       "japanese           1.0        1.0     1.0   2493.0\n",
       "korean             1.0        1.0     1.0   1446.0\n",
       "moroccan           1.0        1.0     1.0   1426.0\n",
       "thai               1.0        1.0     1.0   2697.0\n",
       "vietnamese         1.0        1.0     1.0   1443.0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = label_encoder.inverse_transform(classifier.predict(x_train))\n",
    "y_true = label_encoder.inverse_transform(y_train)\n",
    "\n",
    "print(f'accuracy score on train data: {accuracy_score(y_true, y_pred)}')\n",
    "\n",
    "def report2dict(cr):\n",
    "    rows = []\n",
    "    for row in cr.split(\"\\n\"):\n",
    "        parsed_row = [x for x in row.split(\"  \") if len(x) > 0]\n",
    "        if len(parsed_row) > 0: rows.append(parsed_row)\n",
    "    measures = rows[0]\n",
    "    classes = defaultdict(dict)\n",
    "    for row in rows[1:]:\n",
    "        class_label = row[0]\n",
    "        for j, m in enumerate(measures):\n",
    "            classes[class_label][m.strip()] = float(row[j + 1].strip())\n",
    "    return classes\n",
    "report = classification_report(y_true, y_pred)\n",
    "pd.DataFrame(report2dict(report)).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "16513d3d20bffed6319671539f261e23eda0f245"
   },
   "source": [
    "## 6. Make submission\n",
    "\n",
    "It seems to be working well. Let's make a submission."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "_uuid": "3bdf327cf64fac66819ec6a2bc1ce0c549aed73f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\user\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>cuisine</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18009</td>\n",
       "      <td>irish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>28583</td>\n",
       "      <td>southern_us</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41580</td>\n",
       "      <td>italian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>29752</td>\n",
       "      <td>cajun_creole</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>35687</td>\n",
       "      <td>italian</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id       cuisine\n",
       "0  18009         irish\n",
       "1  28583   southern_us\n",
       "2  41580       italian\n",
       "3  29752  cajun_creole\n",
       "4  35687       italian"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = label_encoder.inverse_transform(classifier.predict(x_test))\n",
    "test['cuisine'] = y_pred\n",
    "test[['id', 'cuisine']].to_csv('submission_external.csv', index=False)\n",
    "test[['id', 'cuisine']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "8c0cfa299375fdd5bb6e785d82198c8dd9e4d696"
   },
   "source": [
    "That's it! Don't trust what I've done here. The score can be better. Please let me know if you find a better approach."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
