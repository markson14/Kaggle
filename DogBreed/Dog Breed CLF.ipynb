{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import keras\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers import Dense, Activation, Flatten, Dropout, GlobalAveragePooling2D\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import keras.applications\n",
    "import os\n",
    "from keras.layers import merge, Input\n",
    "from tqdm import tqdm\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_FOLDER  = 'train/'\n",
    "TEST_FOLDER  = 'test/'\n",
    "train_df = pd.read_csv('labels.csv')\n",
    "\n",
    "top_breeds = sorted(list(train_df['breed'].value_counts().head(20).index))\n",
    "# top_breeds = sorted(list(train_df['breed']))\n",
    "train_df = train_df[train_df['breed'].isin(top_breeds)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "SEED = 9\n",
    "transformation_ratio = .05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.preprocessing.image import load_img\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "DIM = 224\n",
    "\n",
    "train_df['image_path'] = train_df.apply( lambda x: ( TRAIN_FOLDER + x[\"id\"] + \".jpg\" ), axis=1 )\n",
    "\n",
    "train_data = np.array([ img_to_array(load_img(img, target_size=(DIM, DIM))) for img in train_df['image_path'].values.tolist()]).astype('float32')\n",
    "train_labels = train_df['breed']\n",
    "\n",
    "\n",
    "x_train, x_validation, y_train, y_validation = train_test_split(train_data, train_labels, test_size=0.2, stratify=np.array(train_labels), random_state=SEED)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = pd.get_dummies(y_train.reset_index(drop=True), columns=top_breeds).as_matrix()\n",
    "y_validation = pd.get_dummies(y_validation.reset_index(drop=True), columns=top_breeds).as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "breed_nums = len(y_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(rescale=1., \n",
    "                                   rotation_range=30, \n",
    "                                   # zoom_range = 0.3, \n",
    "                                   width_shift_range=0.2,\n",
    "                                   height_shift_range=0.2, \n",
    "                                   horizontal_flip = 'true')\n",
    "train_generator = train_datagen.flow(x_train, y_train, shuffle=False, batch_size=batch_size, seed=10)\n",
    "\n",
    "val_datagen = ImageDataGenerator(rescale = 1.)\n",
    "val_generator = train_datagen.flow(x_validation, y_validation, shuffle=False, batch_size=batch_size, seed=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1747"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_generator.n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      " - 21s - loss: 4.7737 - acc: 0.3109 - val_loss: 2.5835 - val_acc: 0.5034\n",
      "Epoch 2/5\n",
      " - 14s - loss: 2.0085 - acc: 0.5778 - val_loss: 1.8658 - val_acc: 0.5789\n",
      "Epoch 3/5\n",
      " - 15s - loss: 1.6141 - acc: 0.6831 - val_loss: 1.6744 - val_acc: 0.6293\n",
      "Epoch 4/5\n",
      " - 15s - loss: 0.9909 - acc: 0.7234 - val_loss: 1.1006 - val_acc: 0.6384\n",
      "Epoch 5/5\n",
      " - 15s - loss: 0.7251 - acc: 0.7580 - val_loss: 1.0459 - val_acc: 0.6842\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "image_input = Input(shape=(224, 224, 3))\n",
    "base_model = keras.applications.vgg16.VGG16(include_top=False, weights='imagenet', input_shape=(224,224,3))\n",
    "x = base_model.output\n",
    "# x = Flatten()(x)\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(1024, activation='relu', name='fc1')(x)\n",
    "x = Dropout(0.25, name='Dropout1')(x)\n",
    "x = Dense(1024, activation='relu', name='fc2')(x)\n",
    "# x = Dropout(0.5, name='Dropout2')(x)\n",
    "predictions = Dense(breed_nums, activation='softmax', name='output')(x)\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "# optimizer1 = Adam(lr=0.0001, decay=0.005)\n",
    "# optimizer2 = Adam(lr=0.00005, decay=0.005)\n",
    "\n",
    "model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "histroy = model.fit_generator(train_generator,\n",
    "                              steps_per_epoch = train_generator.n/batch_size,\n",
    "                              validation_data = val_generator,\n",
    "                              validation_steps = val_generator.n/batch_size,\n",
    "                              epochs = 5,\n",
    "                              verbose = 2)\n",
    "model.save('VGG16_transferL.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Variable *= will be deprecated. Use variable.assign_mul if you want assignment to the variable value or 'x = x * y' if you want a new python Tensor object.\n",
      "Epoch 1/5\n",
      " - 23s - loss: 0.7975 - acc: 0.7428 - val_loss: 0.8390 - val_acc: 0.7414\n",
      "Epoch 2/5\n",
      " - 21s - loss: 0.4541 - acc: 0.8391 - val_loss: 0.7361 - val_acc: 0.7574\n",
      "Epoch 3/5\n",
      " - 21s - loss: 0.3533 - acc: 0.8803 - val_loss: 0.7940 - val_acc: 0.7826\n",
      "Epoch 4/5\n",
      " - 21s - loss: 0.3265 - acc: 0.8947 - val_loss: 0.6695 - val_acc: 0.8009\n",
      "Epoch 5/5\n",
      " - 21s - loss: 0.2045 - acc: 0.9347 - val_loss: 0.9723 - val_acc: 0.7712\n",
      "Training time: 1.79 mins\n"
     ]
    }
   ],
   "source": [
    "for layer in model.layers[:6]:\n",
    "   layer.trainable = False\n",
    "for layer in model.layers[6:]:\n",
    "   layer.trainable = True\n",
    "\n",
    "optimizer2 = Adam(lr=0.00005, decay=0.005)\n",
    "epoch_num = 10\n",
    "earlystopping = keras.callbacks.EarlyStopping(monitor='val_acc', patience=2, verbose=0, mode='auto')\n",
    "\n",
    "#Begin Model Traininga\n",
    "model.compile(loss='categorical_crossentropy',optimizer=optimizer2,metrics=['accuracy'])\n",
    "t=time.time()\n",
    "#\tt = now()\n",
    "train_history = model.fit_generator(train_generator,\n",
    "                              steps_per_epoch = train_generator.n/batch_size,\n",
    "                              validation_data = val_generator,\n",
    "                              validation_steps = val_generator.n/batch_size,\n",
    "                              epochs = 5,\n",
    "                              verbose = 2)\n",
    "print('Training time: %s mins' % round((time.time()-t)/60, 2))\n",
    "\n",
    "model.save('VGG16_Finetuning3_avg_do0.25.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-857fa1371500>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mpreds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mdf_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'sample_submission.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0msub\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'x_test' is not defined"
     ]
    }
   ],
   "source": [
    "preds = model.predict(x_test, verbose=1)\n",
    "\n",
    "df_test = pd.read_csv('sample_submission.csv')\n",
    "\n",
    "sub = pd.DataFrame(preds)\n",
    "# Set column names to those generated by the one-hot encoding earlier\n",
    "col_names = one_hot.columns.values\n",
    "sub.columns = col_names\n",
    "# Insert the column id from the sample_submission at the start of the data frame\n",
    "sub.insert(0, 'id', df_test['id'])\n",
    "sub.head(5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
